# -*- coding: utf-8 -*-
"""Narayana(MCTGNN)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gd0K75wiQKlPygkojDtTOqGSyWC6_Nty
"""

# !pip install torch_geometric kagglehub networkx matplotlib pandas numpy torchdiffeq

# -*- coding: utf-8 -*-
"""OmNamoAranganatha - Cell 1: Data Loading and Electrode Graph Creation"""

import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import kagglehub
import os

# Function to create a fully connected adjacency matrix
def create_fully_connected_adjacency_matrix(n_electrodes):
    adj_matrix = np.ones((n_electrodes, n_electrodes), dtype=int)
    np.fill_diagonal(adj_matrix, 0)  # No self-loops
    return adj_matrix

# Function to plot the 3D electrode graph
def plot_electrode_graph(adj_matrix, coords):
    G = nx.from_numpy_array(adj_matrix)
    pos = {i: (coords.iloc[i]['x'], coords.iloc[i]['y'], coords.iloc[i]['z']) for i in range(len(coords))}
    fig = plt.figure(figsize=(12, 10))
    ax = fig.add_subplot(111, projection='3d')
    xs, ys, zs = coords['x'], coords['y'], coords['z']
    scatter = ax.scatter(xs, ys, zs, c='b', marker='o', s=50, label='Electrodes')
    for i in range(len(coords)):
        ax.text(coords.iloc[i]['x'], coords.iloc[i]['y'], coords.iloc[i]['z'], f"E{i}", fontsize=8)
    for edge in G.edges():
        i, j = edge
        ax.plot([coords.iloc[i]['x'], coords.iloc[j]['x']],
                [coords.iloc[i]['y'], coords.iloc[j]['y']],
                [coords.iloc[i]['z'], coords.iloc[j]['z']],
                c='gray', alpha=0.1)
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.legend()
    plt.title('Electrode Graph with Labels (162 Electrodes)')
    plt.savefig('electrode_graph.png')
    plt.show()
    print("Saved electrode graph to 'electrode_graph.png'")

# Load and clean coordinates
print("Downloading electrode coordinates dataset...")
path = kagglehub.dataset_download("arunramponnambalam/electrodes-coordinates")
print("Path to dataset files:", path)
dataset_files = os.listdir(path)
print("Files in dataset:", dataset_files)
coords_file = os.path.join(path, 'electrodesdata.csv')
coords = pd.read_csv(coords_file, usecols=[0, 1, 2], names=['x', 'y', 'z'], header=0)

# Remove corrupted electrodes
corrupted_indices = [0, 16, 23, 24, 26, 31, 38, 63, 92, 96, 99, 100, 101, 102, 108, 111, 112, 113, 114, 122, 128, 129, 139, 142, 145, 146, 147, 148, 170, 177, 192, 193]
valid_indices = [i for i in range(len(coords)) if i not in corrupted_indices]
coords = coords.iloc[valid_indices].reset_index(drop=True)
print(f"Removed {len(corrupted_indices)} corrupted electrodes. Remaining: {len(coords)}")

if len(coords) != 162:
    raise ValueError(f"Expected 162 electrodes after cleaning, but found {len(coords)}")

# Create adjacency matrix and visualize
adj_matrix = create_fully_connected_adjacency_matrix(n_electrodes=162)
plot_electrode_graph(adj_matrix, coords)
print(f"Adjacency matrix shape: {adj_matrix.shape}")
print(f"Number of connections: {np.sum(adj_matrix) // 2}")

"""## MCTGNN-DOPRI5"""


import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
import kagglehub
import os
import logging
from torchdiffeq import odeint
import matplotlib.pyplot as plt
from joblib import Parallel, delayed
import warnings
import gc

# Logging and device setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
if not torch.cuda.is_available():
    raise RuntimeError("CUDA is not available. Please set Colab runtime to GPU.")
print(f"CUDA Device: {torch.cuda.get_device_name(0)}")

# Constants - optimized for neural dynamics
NUM_NODES = 162
IN_CHANNELS = 1
MAX_SEQ_LENGTH = 5000
BATCH_SIZE = 2
LEARNING_RATE = 0.0005
EPOCHS = 50
HIDDEN_DIM = 32
SUBSAMPLE_FACTOR = 5 # Balance between accuracy and speed

# Enable cuDNN benchmark for faster training
torch.backends.cudnn.benchmark = True

# Helper Functions
def parse_numeric_string(s):
    try:
        if not isinstance(s, str):
            return None
        s = s.strip('[]').replace('\n', ' ').replace('...', '0').strip()
        if not s or s.isspace():
            return None
        values = [float(x) for x in s.split() if x.strip() and x.replace('.', '').replace('-', '').isdigit()]
        return np.array(values) if values else None
    except Exception as e:
        logger.warning(f"Failed to parse string: {s[:30]}... - Error: {str(e)}")
        return None

# Dataset Class with improved progress tracking
class NeuralSignalDataset(Dataset):
    def __init__(self, data_df, coords_df, max_seq_length=MAX_SEQ_LENGTH, normalize=True,
                 chunk_min_size=20, max_chunks=130):
        self.data = data_df
        self.coords = coords_df
        self.max_seq_length = max_seq_length
        self.normalize = normalize
        self.chunk_min_size = chunk_min_size
        self.max_chunks = max_chunks
        self.valid_indices = [i for i in range(194) if i not in [0, 16, 23, 24, 26, 31, 38, 63, 92, 96, 99, 100, 101, 102, 108, 111, 112, 113, 114, 122, 128, 129, 139, 142, 145, 146, 147, 148, 170, 177, 192, 193]]
        self.process_data()

    def process_data(self):
        """Process the neural data into chunks based on stimulus changes."""
        print("Chunking data dynamically based on stimulus changes...")
        total_rows = len(self.data)
        chunked_data = []
        actual_lengths = []
        current_activity = None
        current_chunk = []

        # Setup progress bar
        progress_bar = tqdm(range(total_rows), desc="Processing rows")

        # Process row by row with original chunking logic
        processed_count = 0
        skipped_count = 0
        chunk_count = 0

        for idx in progress_bar:
            try:
                electrode_str = self.data.iloc[idx]['data']
                electrode_values = parse_numeric_string(electrode_str)
                if electrode_values is None or len(electrode_values) != 194:
                    skipped_count += 1
                    continue
                electrode_values = electrode_values[self.valid_indices]
                if len(electrode_values) != NUM_NODES:
                    skipped_count += 1
                    continue

                activity = self.data.iloc[idx]['activity']
                processed_count += 1

                if current_activity is None:
                    current_activity = activity
                    current_chunk = [electrode_values]
                elif activity != current_activity:
                    if len(current_chunk) > self.chunk_min_size and len(chunked_data) < self.max_chunks:
                        chunked_data.append(np.vstack(current_chunk))
                        actual_lengths.append(len(current_chunk))
                        chunk_count += 1
                    current_chunk = [electrode_values]
                    current_activity = activity
                else:
                    current_chunk.append(electrode_values)

                # Update progress bar description with stats
                if idx % 100 == 0:
                    progress_bar.set_postfix({
                        'processed': processed_count,
                        'skipped': skipped_count,
                        'chunks': chunk_count,
                        'current_chunk_size': len(current_chunk)
                    })

            except Exception as e:
                logger.error(f"Error processing row {idx}: {str(e)}")
                skipped_count += 1
                continue

        # Process the last chunk if needed
        if current_chunk and len(current_chunk) > self.chunk_min_size and len(chunked_data) < self.max_chunks:
            chunked_data.append(np.vstack(current_chunk))
            actual_lengths.append(len(current_chunk))
            chunk_count += 1

        if not chunked_data:
            raise ValueError("No valid data chunks processed.")

        print(f"Processing complete! Found {processed_count} valid rows, created {chunk_count} chunks")

        # Setup progress bar for padding and processing
        print("Preparing final dataset...")
        self.electrode_data = []
        self.actual_lengths = []

        for chunk_idx, (chunk, actual_length) in enumerate(zip(chunked_data, actual_lengths)):
            print(f"Processing chunk {chunk_idx+1}/{len(chunked_data)}, length={actual_length}")
            if actual_length > self.max_seq_length:
                self.electrode_data.append(chunk[:self.max_seq_length])
                self.actual_lengths.append(self.max_seq_length)
            else:
                pad_len = self.max_seq_length - actual_length
                self.electrode_data.append(np.pad(chunk, ((0, pad_len), (0, 0)), mode='constant'))
                self.actual_lengths.append(actual_length)

        self.electrode_data = np.stack(self.electrode_data)
        print(f"Stacked data shape before normalization: {self.electrode_data.shape}")

        if self.normalize:
            print("Normalizing data...")
            try:
                scaler = StandardScaler()
                reshaped_data = self.electrode_data.reshape(-1, NUM_NODES)
                normalized_data = scaler.fit_transform(reshaped_data)
                self.electrode_data = normalized_data.reshape(self.electrode_data.shape)
            except Exception as e:
                logger.error(f"Error during normalization: {str(e)}")
                # If standard scaling fails, use a simpler approach
                mean = np.mean(self.electrode_data)
                std = np.std(self.electrode_data) + 1e-8
                self.electrode_data = (self.electrode_data - mean) / std

        print(f"Dataset preparation complete! Final shape: {self.electrode_data.shape}")

    def __len__(self):
        return len(self.electrode_data)

    def __getitem__(self, idx):
        sequences = self.electrode_data[idx]
        actual_length = self.actual_lengths[idx]
        return torch.FloatTensor(sequences).unsqueeze(-1), torch.tensor(actual_length, dtype=torch.long)

# ODE Function optimized for LSODA solver
class StableGNNFunc(nn.Module):
    def __init__(self, hidden_dim, adj_matrix):
        super(StableGNNFunc, self).__init__()
        self.hidden_dim = hidden_dim
        self.adj_matrix = adj_matrix.clone()  # Create a clone to avoid reference issues

        # Multi-layer GNN with LayerNorm for stability
        self.gnn_layer = nn.Sequential(
            nn.Linear(2 * hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.SiLU(),  # SiLU is smoother than ReLU, helping with ODE integration
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim)
        )

        # Activity-state dynamics
        self.dx_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh()  # Bounded activation for stability
        )

        # Memory-state dynamics
        self.dm_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh()  # Bounded activation for stability
        )

        # Coefficients tuned for neuronal dynamics
        self.diffusion_coef = 0.02  # Spatial spread parameter
        self.decay_coef = 0.03     # Neural decay parameter
        self.scale_factor = 2.0    # Overall dynamics speed

    # Override the to() method to ensure adj_matrix moves with the model
    def to(self, *args, **kwargs):
        self.adj_matrix = self.adj_matrix.to(*args, **kwargs)
        return super(StableGNNFunc, self).to(*args, **kwargs)

    def forward(self, t, z):
        # Get shape and device info
        batch_size, num_nodes, total_dim = z.shape
        device_z = z.device

        # Make sure adj_matrix is on the same device as z
        if self.adj_matrix.device != device_z:
            self.adj_matrix = self.adj_matrix.to(device_z)

        assert total_dim == 2 * self.hidden_dim, f"Expected dim {2 * self.hidden_dim}, got {total_dim}"

        # State decomposition
        x = z[:, :, :self.hidden_dim]  # Neural activity state
        m = z[:, :, self.hidden_dim:]  # Memory component

        # Check for NaN inputs and replace if needed
        if torch.isnan(z).any():
            if torch.isnan(x).any():
                x = torch.nan_to_num(x, nan=0.0)
            if torch.isnan(m).any():
                m = torch.nan_to_num(m, nan=0.0)
            z_cat = torch.cat([x, m], dim=-1)
        else:
            # Concatenate states
            z_cat = torch.cat([x, m], dim=-1)

        # Apply GNN layer
        transformed = self.gnn_layer(z_cat)

        # Normalize to prevent extreme values
        transformed = F.normalize(transformed, p=2, dim=-1) * (self.hidden_dim**0.5)

        # Graph diffusion - node interactions through adjacency matrix
        neighbor_influence = torch.matmul(self.adj_matrix.float(), transformed)

        # Calculate dynamics with scale factor
        dx_dt = self.scale_factor * self.dx_head(
            transformed + self.diffusion_coef * neighbor_influence - self.decay_coef * x
        )
        dm_dt = self.scale_factor * self.dm_head(
            transformed + self.diffusion_coef * neighbor_influence
        )

        # Combine state derivatives
        dz_dt = torch.cat([dx_dt, dm_dt], dim=-1)

        # Add gradient norm clipping for stability - critical for LSODA
        norm = torch.norm(dz_dt, dim=-1, keepdim=True)
        max_norm = 10.0  # Max gradient magnitude
        scale = torch.clamp(max_norm / (norm + 1e-8), max=1.0)
        dz_dt = dz_dt * scale

        # Check for NaN and replace if necessary
        if torch.isnan(dz_dt).any():
            dz_dt = torch.nan_to_num(dz_dt, nan=0.0)

        return dz_dt

# Neural ODE with LSODA solver
class StableNeuralODEGNN(nn.Module):
    def __init__(self, in_channels, hidden_dim, adj_matrix):
        super(StableNeuralODEGNN, self).__init__()
        self.hidden_dim = hidden_dim
        self.adj_matrix = adj_matrix.clone()  # Clone to avoid reference issues

        # Encoder network: maps input to initial ODE state
        self.encoder = nn.Sequential(
            nn.Linear(in_channels, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 2 * hidden_dim)
        )

        self.ode_func = StableGNNFunc(hidden_dim, adj_matrix)

    def forward(self, x):
        batch_size, seq_len, num_nodes, channels = x.shape

        # Get initial state from first time step
        initial_x = x[:, 0, :, :]
        z0 = self.encoder(initial_x)

        # Create integration time points - sparse for efficiency
        integration_time = torch.linspace(0, seq_len-1, seq_len//SUBSAMPLE_FACTOR + 1, dtype=torch.float32).to(device)

        print(f"Starting LSODA integration with {len(integration_time)} time points...")

        # LSODA needs CPU tensors
        integration_time_cpu = integration_time.cpu()
        z0_cpu = z0.cpu()

        # Create CPU version of ODE function
        ode_func_cpu = StableGNNFunc(self.hidden_dim, self.adj_matrix.cpu())
        ode_func_cpu.load_state_dict(self.ode_func.state_dict())
        ode_func_cpu.to('cpu')

        # Make sure everything is on CPU
        assert z0_cpu.device.type == 'cpu', f"Expected CPU tensor, got {z0_cpu.device}"
        assert ode_func_cpu.adj_matrix.device.type == 'cpu', f"Expected CPU tensor, got {ode_func_cpu.adj_matrix.device}"

        # Parameters optimized for LSODA with neural data
        rtol = 1e-2
        atol = 1e-3

        # Suppress warnings during integration
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=UserWarning)

            try:
                # Integrate with LSODA solver
                solution = odeint(
                    ode_func_cpu,
                    z0_cpu,
                    integration_time_cpu,
                    method='scipy_solver',
                    options={'method': 'LSODA'},
                    rtol=rtol,
                    atol=atol
                )

                print(f"LSODA integration complete. Solution shape: {solution.shape}")

                # Check for NaN values in the solution
                if torch.isnan(solution).any():
                    print("Warning: NaN values detected in ODE solution. Replacing with zeros.")
                    solution = torch.nan_to_num(solution, nan=0.0)

                # Move solution back to GPU
                solution = solution.to(device)

                # Interpolate to get full sequence
                full_solution = self._interpolate_solution(solution, integration_time, seq_len, batch_size, num_nodes)

                return full_solution

            except Exception as e:
                logger.error(f"LSODA integration failed: {str(e)}")
                print(f"Error: {str(e)}. Falling back to dopri5 solver.")

                # Fall back to dopri5 on original device
                try:
                    solution = odeint(
                        self.ode_func,
                        z0,
                        integration_time,
                        method='dopri5',
                        rtol=rtol,
                        atol=atol
                    )

                    # Interpolate solution
                    full_solution = self._interpolate_solution(solution, integration_time, seq_len, batch_size, num_nodes)
                    return full_solution

                except Exception as e2:
                    logger.error(f"Fallback integration also failed: {str(e2)}")
                    print("Using simple time-stepping as final fallback")

                    # Ultimate fallback - simple forward evolution
                    return self._fallback_integration(z0, seq_len, batch_size, num_nodes)

    def _interpolate_solution(self, solution, integration_time, seq_len, batch_size, num_nodes):
        """Interpolate ODE solution to full sequence length"""
        # Prepare for interpolation
        full_time = torch.arange(seq_len, dtype=torch.float32).to(device)
        full_solution = torch.zeros(seq_len, batch_size, num_nodes, 2 * self.hidden_dim, device=device)

        # Get indices for interpolation
        idx = torch.searchsorted(integration_time, full_time)
        idx = torch.clamp(idx, 1, len(integration_time) - 1)

        # Vectorized approach to interpolation
        t0 = integration_time[idx - 1].unsqueeze(1).unsqueeze(1).unsqueeze(1)
        t1 = integration_time[idx].unsqueeze(1).unsqueeze(1).unsqueeze(1)

        # Extract solution values at these indices
        solution_shape = solution.shape
        idx_expanded = idx.view(-1, 1, 1, 1).expand(-1, batch_size, num_nodes, 2 * self.hidden_dim)
        idx_prev = (idx - 1).view(-1, 1, 1, 1).expand(-1, batch_size, num_nodes, 2 * self.hidden_dim)

        try:
            # Try vectorized gathering
            v0 = torch.gather(solution, 0, idx_prev)
            v1 = torch.gather(solution, 0, idx_expanded)

            # Calculate weights
            weights = ((full_time - t0) / (t1 - t0 + 1e-8)).clamp(0, 1)

            # Interpolate
            full_solution = v0 + weights * (v1 - v0)

        except Exception as e:
            # Fall back to loop-based interpolation
            print(f"Vectorized interpolation failed: {str(e)}. Using loop-based interpolation.")

            for b in range(batch_size):
                for n in range(num_nodes):
                    for d in range(2 * self.hidden_dim):
                        t0 = integration_time[idx - 1]
                        t1 = integration_time[idx]
                        v0 = solution[idx - 1, b, n, d]
                        v1 = solution[idx, b, n, d]
                        weights = (full_time - t0) / (t1 - t0 + 1e-8)
                        full_solution[:, b, n, d] = v0 + (v1 - v0) * weights.clamp(0, 1)

        return full_solution

    def _fallback_integration(self, z0, seq_len, batch_size, num_nodes):
        """Fallback integration using simple time-stepping"""
        full_solution = torch.zeros(seq_len, batch_size, num_nodes, 2 * self.hidden_dim, device=device)
        state = z0
        full_solution[0] = state

        for t in range(1, seq_len):
            # Simple Euler step
            derivative = self.ode_func(torch.tensor(float(t), device=device), state)
            state = state + derivative * 1.0  # dt = 1.0
            full_solution[t] = state

            # Periodically clean up memory
            if t % 100 == 0:
                torch.cuda.empty_cache()

        return full_solution

# Enhanced Temporal GNN - for neural prediction
class EnhancedTemporalGNN(nn.Module):
    def __init__(self, in_channels, hidden_dim, adj_matrix):
        super(EnhancedTemporalGNN, self).__init__()
        self.neural_ode_gnn = StableNeuralODEGNN(in_channels, hidden_dim, adj_matrix)

        # Multi-layer decoder
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, in_channels)
        )

    def forward(self, x):
        # Get ODE solution
        solution = self.neural_ode_gnn(x)

        # Extract activity state
        pred_x = solution[:, :, :, :self.neural_ode_gnn.hidden_dim]

        # Apply decoder to get predictions
        pred_observations = self.decoder(pred_x)

        # Permute to match expected shape
        pred_sequences = pred_observations.permute(1, 0, 2, 3)

        return pred_sequences, solution

# Create correlation adjacency matrix
def create_correlation_adjacency_matrix(data, valid_indices, n_samples=50000, threshold=0.5):
    print(f"Computing correlation adjacency matrix across {n_samples} timestamps...")

    sample_data = []
    for idx in tqdm(range(min(n_samples, len(data))), desc="Building correlation matrix"):
        try:
            electrode_str = data.iloc[idx]['data']
            electrode_values = parse_numeric_string(electrode_str)
            if electrode_values is not None and len(electrode_values) == 194:
                sample_data.append(electrode_values[valid_indices])
        except Exception as e:
            logger.error(f"Error processing index {idx}: {str(e)}")
            continue

    if not sample_data:
        raise ValueError("No valid samples collected for adjacency matrix")

    sample_data = np.array(sample_data).T

    print(f"Computing correlation coefficients for {len(sample_data)} nodes...")
    corr_matrix = np.corrcoef(sample_data)
    corr_matrix = np.nan_to_num(corr_matrix)

    print(f"Creating adjacency matrix with threshold {threshold}...")
    adj_matrix = (np.abs(corr_matrix) > threshold).astype(np.float32)
    np.fill_diagonal(adj_matrix, 0)

    edges = adj_matrix.sum()
    print(f"Created adjacency matrix with {edges} edges")

    return torch.FloatTensor(adj_matrix).to(device)

# Main function with optimized training
def main():
    try:
        os.makedirs("results", exist_ok=True)

        # Data loading
        print("Loading electrode coordinates...")
        coords_path = kagglehub.dataset_download("arunramponnambalam/electrodes-coordinates")
        coords_file = os.path.join(coords_path, "electrodesdata.csv")
        coords = pd.read_csv(coords_file, usecols=[0, 1, 2], names=['x', 'y', 'z'], header=0)
        valid_indices = [i for i in range(len(coords)) if i not in [0, 16, 23, 24, 26, 31, 38, 63, 92, 96, 99, 100, 101, 102, 108, 111, 112, 113, 114, 122, 128, 129, 139, 142, 145, 146, 147, 148, 170, 177, 192, 193]]
        coords = coords.iloc[valid_indices].reset_index(drop=True)

        print("Loading neural activity data...")
        data_path = kagglehub.dataset_download("nocopyrights/image-stimulus-timestamp-data")
        data_file = os.path.join(data_path, "merged_data.csv")
        data = pd.read_csv(data_file)
        print(f"Loaded dataset with {len(data)} samples")

        data = data[~(data['activity'].str.startswith('sscr', na=False) | data['activity'].str.startswith('sscr2', na=False))].reset_index(drop=True)
        print(f"Dataset after filtering: {len(data)} samples")

        print("Creating adjacency matrix...")
        adj_matrix = create_correlation_adjacency_matrix(data, valid_indices)

        print("Initializing dataset...")
        dataset = NeuralSignalDataset(data, coords)

        # Free up memory
        del data
        gc.collect()
        torch.cuda.empty_cache()

        print("Creating data loader...")
        try:
            train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
        except Exception as e:
            print(f"Error with multiple workers: {str(e)}, trying with 0 workers")
            train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)

        # Model initialization and training setup
        print("Initializing model...")
        model = EnhancedTemporalGNN(IN_CHANNELS, HIDDEN_DIM, adj_matrix).to(device)

        # Use Adam with carefully tuned parameters
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=LEARNING_RATE,
            weight_decay=1e-6,
            eps=1e-8
        )

        # Learning rate scheduler for better convergence
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='min',
            factor=0.7,
            patience=4,
            verbose=True
        )

        # Keep track of best model
        best_loss = float('inf')
        best_model_state = None

        # Training loop
        print("Starting training...")
        for epoch in range(EPOCHS):
            model.train()
            total_loss = 0
            batch_count = 0

            # Training loop with progress bar
            train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")

            for sequences, actual_lengths in train_pbar:
                try:
                    sequences = sequences.to(device)
                    actual_lengths = actual_lengths.to(device)

                    # Zero gradients
                    optimizer.zero_grad()

                    # Forward pass
                    pred_sequences, _ = model(sequences)

                    # Create mask for sequence lengths
                    batch_size, seq_len, _, _ = sequences.shape
                    mask = torch.zeros(batch_size, seq_len, device=device)
                    for b in range(batch_size):
                        mask[b, :actual_lengths[b]] = 1

                    # Masked loss calculation
                    loss = ((pred_sequences - sequences) ** 2 * mask.unsqueeze(-1).unsqueeze(-1)).sum() / (mask.sum() * NUM_NODES * IN_CHANNELS)

                    # Check for NaN loss
                    if torch.isnan(loss) or torch.isinf(loss):
                        print("Invalid loss detected, skipping batch")
                        continue

                    # Backward pass and optimization
                    loss.backward()

                    # Conservative gradient clipping
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.25)

                    optimizer.step()

                    # Update statistics
                    total_loss += loss.item()
                    batch_count += 1

                    # Update progress bar
                    train_pbar.set_postfix({'loss': loss.item()})

                    # Free GPU memory
                    if batch_count % 5 == 0:
                        torch.cuda.empty_cache()

                except Exception as e:
                    logger.error(f"Error during training batch: {str(e)}")
                    continue

            # Calculate average loss
            avg_loss = total_loss / max(1, batch_count)
            print(f"Epoch [{epoch+1}/{EPOCHS}], Reconstruction Loss: {avg_loss:.4f}")

            # Update learning rate with scheduler
            scheduler.step(avg_loss)

            # Save best model
            if avg_loss < best_loss:
                best_loss = avg_loss
                best_model_state = model.state_dict().copy()
                print(f"New best model saved! Loss: {best_loss:.4f}")

        # Load best model for evaluation
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
            print(f"Loaded best model with loss: {best_loss:.4f}")

            # Save model weights
            torch.save(model.state_dict(), "results/ecog_ode_model_lsoda.pt")
            print("Model saved to results/ecog_ode_model_lsoda.pt")

        # Evaluation
        print("Running evaluation...")
        model.eval()
        with torch.no_grad():
            all_pred_sequences = []
            all_actual_sequences = []
            all_masks = []

            # Evaluation loop with progress bar
            for sequences, actual_lengths in tqdm(train_loader, desc="Evaluating"):
                try:
                    sequences = sequences.to(device)
                    actual_lengths = actual_lengths.to(device)

                    # Forward pass
                    pred_sequences, solution = model(sequences)

                    # Create evaluation masks
                    batch_size, seq_len, _, _ = sequences.shape
                    masks = []
                    for b in range(batch_size):
                        mask = torch.zeros(seq_len)
                        mask[:actual_lengths[b]] = 1
                        masks.append(mask)

                    # Store predictions, actual values, and masks
                    all_pred_sequences.append(pred_sequences.cpu().numpy())
                    all_actual_sequences.append(sequences.cpu().numpy())
                    all_masks.append(torch.stack(masks).numpy())

                except Exception as e:
                    logger.error(f"Error during evaluation: {str(e)}")
                    continue

            # Concatenate results
            pred_sequences = np.concatenate(all_pred_sequences, axis=0)
            actual_sequences = np.concatenate(all_actual_sequences, axis=0)
            masks = np.concatenate(all_masks, axis=0)

            # Calculate mean squared error on actual (non-padded) data points
            mse = np.mean(((pred_sequences - actual_sequences)**2 * masks[:, :, np.newaxis, np.newaxis]).sum() /
                         masks.sum())
            print(f"Mean Squared Error on non-padded data: {mse:.6f}")

            # Generate plots
            print("Generating visualization plots...")

            # Plot multiple nodes for better visualization
            sample_idx = 0
            for node_idx in [0, 20, 40, 80]:
                try:
                    plt.figure(figsize=(12, 6))

                    # Only plot actual sequence length (not padded)
                    actual_length = int(masks[sample_idx].sum())
                    plt.plot(actual_sequences[sample_idx, :actual_length, node_idx, 0], label='Actual')
                    plt.plot(pred_sequences[sample_idx, :actual_length, node_idx, 0], label='Predicted')
                    plt.title(f"Neural Activity Dynamics (Sample {sample_idx}, Node {node_idx})")
                    plt.xlabel("Time Steps")
                    plt.ylabel("Normalized Activity")
                    plt.legend()
                    plt.savefig(f"results/dynamics_node_{node_idx}_lsoda.png")
                    plt.close()
                except Exception as e:
                    logger.error(f"Error creating plot for node {node_idx}: {str(e)}")
                    continue

            print("Saved dynamics visualizations to results folder")

    except Exception as e:
        logger.error(f"Error in main: {str(e)}")
        print(f"Caught exception: {str(e)}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"Error in main: {str(e)}")
        print(f"Caught exception: {str(e)}")

